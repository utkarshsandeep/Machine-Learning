{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= [80 80]\n",
      "W= [79.2 79.2]\n",
      "W= [78.4 78.4]\n",
      "W= [77.6 77.6]\n",
      "W= [76.8 76.8]\n",
      "W= [76. 76.]\n",
      "W= [75.2 75.2]\n",
      "W= [74.4 74.4]\n",
      "W= [73.6 73.6]\n",
      "W= [72.8 72.8]\n",
      "W= [72. 72.]\n",
      "W= [71.2 71.2]\n",
      "W= [70.4 70.4]\n",
      "W= [69.6 69.6]\n",
      "W= [68.8 68.8]\n",
      "W= [68. 68.]\n",
      "W= [67.2 67.2]\n",
      "W= [66.4 66.4]\n",
      "W= [65.6 65.6]\n",
      "W= [64.8 64.8]\n",
      "W= [64. 64.]\n",
      "W= [63.2 63.2]\n",
      "W= [62.4 62.4]\n",
      "W= [61.6 61.6]\n",
      "W= [60.8 60.8]\n",
      "W= [60. 60.]\n",
      "W= [59.2 59.2]\n",
      "W= [58.4 58.4]\n",
      "W= [57.6 57.6]\n",
      "W= [56.8 56.8]\n",
      "W= [56. 56.]\n",
      "W= [55.2 55.2]\n",
      "W= [54.4 54.4]\n",
      "W= [53.6 53.6]\n",
      "W= [52.8 52.8]\n",
      "W= [52. 52.]\n",
      "W= [51.2 51.2]\n",
      "W= [50.4 50.4]\n",
      "W= [49.6 49.6]\n",
      "W= [48.8 48.8]\n",
      "W= [48. 48.]\n",
      "W= [47.2 47.2]\n",
      "W= [46.4 46.4]\n",
      "W= [45.6 45.6]\n",
      "W= [44.8 44.8]\n",
      "W= [44. 44.]\n",
      "W= [43.2 43.2]\n",
      "W= [42.4 42.4]\n",
      "W= [41.6 41.6]\n",
      "W= [40.8 40.8]\n",
      "W= [40. 40.]\n",
      "W= [39.2 39.2]\n",
      "W= [38.4 38.4]\n",
      "W= [37.6 37.6]\n",
      "W= [36.8 36.8]\n",
      "W= [36. 36.]\n",
      "W= [35.2 35.2]\n",
      "W= [34.4 34.4]\n",
      "W= [33.6 33.6]\n",
      "W= [32.8 32.8]\n",
      "W= [32. 32.]\n",
      "W= [31.2 31.2]\n",
      "W= [30.4 30.4]\n",
      "W= [29.6 29.6]\n",
      "W= [28.8 28.8]\n",
      "W= [28. 28.]\n",
      "W= [27.2 27.2]\n",
      "W= [26.4 26.4]\n",
      "W= [25.6 25.6]\n",
      "W= [24.8 24.8]\n",
      "W= [24. 24.]\n",
      "W= [23.2 23.2]\n",
      "W= [22.4 22.4]\n",
      "W= [21.6 21.6]\n",
      "W= [20.8 20.8]\n",
      "W= [20. 20.]\n",
      "W= [19.2 19.2]\n",
      "W= [18.4 18.4]\n",
      "W= [17.6 17.6]\n",
      "W= [16.8 16.8]\n",
      "W= [16. 16.]\n",
      "W= [15.2 15.2]\n",
      "W= [14.4 14.4]\n",
      "W= [13.6 13.6]\n",
      "W= [12.8 12.8]\n",
      "W= [12. 12.]\n",
      "W= [11.2 11.2]\n",
      "W= [10.4 10.4]\n",
      "W= [9.6 9.6]\n",
      "W= [8.8 8.8]\n",
      "W= [8. 8.]\n",
      "W= [7.2 7.2]\n",
      "W= [6.4 6.4]\n",
      "W= [5.6 5.6]\n",
      "W= [4.8 4.8]\n",
      "W= [4. 4.]\n",
      "W= [3.2 3.2]\n",
      "W= [2.4 2.4]\n",
      "W= [1.6 1.6]\n",
      "W= [0.8 0.8]\n",
      "W= [1.50324198e-13 1.50324198e-13]\n",
      "W= [-0.8 -0.8]\n",
      "Optimized a step.\n",
      "---- 0.7999999999998497 0.0\n",
      "latest_optimum 2.39999999999985\n",
      "W= [2.4 2.4]\n",
      "W= [2.32 2.32]\n",
      "W= [2.24 2.24]\n",
      "W= [2.16 2.16]\n",
      "W= [2.08 2.08]\n",
      "W= [2. 2.]\n",
      "W= [1.92 1.92]\n",
      "W= [1.84 1.84]\n",
      "W= [1.76 1.76]\n",
      "W= [1.68 1.68]\n",
      "W= [1.6 1.6]\n",
      "W= [1.52 1.52]\n",
      "W= [1.44 1.44]\n",
      "W= [1.36 1.36]\n",
      "W= [1.28 1.28]\n",
      "W= [1.2 1.2]\n",
      "W= [1.12 1.12]\n",
      "W= [1.04 1.04]\n",
      "W= [0.96 0.96]\n",
      "W= [0.88 0.88]\n",
      "W= [0.8 0.8]\n",
      "W= [0.72 0.72]\n",
      "W= [0.64 0.64]\n",
      "W= [0.56 0.56]\n",
      "W= [0.48 0.48]\n",
      "W= [0.4 0.4]\n",
      "W= [0.32 0.32]\n",
      "W= [0.24 0.24]\n",
      "W= [0.16 0.16]\n",
      "W= [0.08 0.08]\n",
      "W= [-1.51240132e-13 -1.51240132e-13]\n",
      "Optimized a step.\n",
      "---- 0.3199999999998488 0.4000000000000128\n",
      "latest_optimum 0.47999999999984877\n",
      "W= [0.48 0.48]\n",
      "W= [0.472 0.472]\n",
      "W= [0.464 0.464]\n",
      "W= [0.456 0.456]\n",
      "W= [0.448 0.448]\n",
      "W= [0.44 0.44]\n",
      "W= [0.432 0.432]\n",
      "W= [0.424 0.424]\n",
      "W= [0.416 0.416]\n",
      "W= [0.408 0.408]\n",
      "W= [0.4 0.4]\n",
      "W= [0.392 0.392]\n",
      "W= [0.384 0.384]\n",
      "W= [0.376 0.376]\n",
      "W= [0.368 0.368]\n",
      "W= [0.36 0.36]\n",
      "W= [0.352 0.352]\n",
      "W= [0.344 0.344]\n",
      "W= [0.336 0.336]\n",
      "W= [0.328 0.328]\n",
      "W= [0.32 0.32]\n",
      "W= [0.312 0.312]\n",
      "W= [0.304 0.304]\n",
      "W= [0.296 0.296]\n",
      "W= [0.288 0.288]\n",
      "W= [0.28 0.28]\n",
      "W= [0.272 0.272]\n",
      "W= [0.264 0.264]\n",
      "W= [0.256 0.256]\n",
      "W= [0.248 0.248]\n",
      "W= [0.24 0.24]\n",
      "W= [0.232 0.232]\n",
      "W= [0.224 0.224]\n",
      "W= [0.216 0.216]\n",
      "W= [0.208 0.208]\n",
      "W= [0.2 0.2]\n",
      "W= [0.192 0.192]\n",
      "W= [0.184 0.184]\n",
      "W= [0.176 0.176]\n",
      "W= [0.168 0.168]\n",
      "W= [0.16 0.16]\n",
      "W= [0.152 0.152]\n",
      "W= [0.144 0.144]\n",
      "W= [0.136 0.136]\n",
      "W= [0.128 0.128]\n",
      "W= [0.12 0.12]\n",
      "W= [0.112 0.112]\n",
      "W= [0.104 0.104]\n",
      "W= [0.096 0.096]\n",
      "W= [0.088 0.088]\n",
      "W= [0.08 0.08]\n",
      "W= [0.072 0.072]\n",
      "W= [0.064 0.064]\n",
      "W= [0.056 0.056]\n",
      "W= [0.048 0.048]\n",
      "W= [0.04 0.04]\n",
      "W= [0.032 0.032]\n",
      "W= [0.024 0.024]\n",
      "W= [0.016 0.016]\n",
      "W= [0.008 0.008]\n",
      "W= [-1.51600954e-13 -1.51600954e-13]\n",
      "Optimized a step.\n",
      "---- 0.23199999999984855 0.11999999999965638\n",
      "latest_optimum 0.24799999999984856\n",
      "[1 7] : 1.271999999999435\n",
      "[2 8] : 1.271999999999435\n",
      "[3 8] : 1.0399999999995864\n",
      "[5 1] : 1.0479999999990506\n",
      "[ 6 -1] : 1.7439999999985962\n",
      "[7 3] : 1.0479999999990506\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-6d8e5c3c3609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m               \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m               [5,8]]\n\u001b[1;32m--> 156\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new feature ------'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-6d8e5c3c3609>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mclassification\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassification\u001b[0m \u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mclassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29852ae9a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use('ggplot')\n",
    "\n",
    "class Support_Vector_Machine:\n",
    "    def __init__(self, visualization=True):\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "    # train\n",
    "    def fit(self, data):\n",
    "        self.data = data\n",
    "        # { ||w||: [w,b] }\n",
    "        opt_dict = {}\n",
    "\n",
    "        transforms = [[1,1],\n",
    "                      [-1,1],\n",
    "                      [-1,-1],\n",
    "                      [1,-1]]\n",
    "\n",
    "        all_data = []\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset:\n",
    "                    all_data.append(feature)   #[1, 7, 2, 8, 3, 8, 5, 1, 6, -1, 7, 3]\n",
    "\n",
    "        self.max_feature_value = max(all_data)  #8\n",
    "        self.min_feature_value = min(all_data)#-1\n",
    "        all_data = None\n",
    "        # support vectors yi(xi.w+b) = 1\n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                      self.max_feature_value * 0.01,\n",
    "                      # point of expense:\n",
    "                      self.max_feature_value * 0.001,\n",
    "                      #self.max_feature_value * 0.0001\n",
    "                      ]\n",
    "        # extremely expensive\n",
    "        b_range_multiple = 2\n",
    "        # we dont need to take as small of steps\n",
    "        # with b as we do w\n",
    "        b_multiple = 5\n",
    "        latest_optimum = self.max_feature_value*10\n",
    "        \n",
    "        for step in step_sizes: #0.1,0.01,0.002\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            #print('W=',w) [80,80] , [2.4,2.4] , [0.48,0.48]\n",
    "            #print('-----')\n",
    "            # we can do this because convex\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        # \n",
    "                        # yi(xi.w+b) >= 1\n",
    "                        # \n",
    "                        # #### add a break here later..\n",
    "                        for i in self.data:  # -1 , +1\n",
    "                            for xi in self.data[i]:\n",
    "                                yi=i\n",
    "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
    "                                    found_option = False\n",
    "                                    #print(xi,':',yi*(np.dot(w_t,xi)+b))\n",
    "                                    \n",
    "                        if found_option:\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
    "                print('W=',w)\n",
    "                if w[0] < 0:\n",
    "                    optimized = True\n",
    "                    print('Optimized a step.')\n",
    "                else:\n",
    "                    w = w - step\n",
    "\n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            #||w|| : [w,b]\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "            print('----',opt_choice[0][0],self.b)\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "            print('latest_optimum',latest_optimum)\n",
    "            \n",
    "        for i in self.data:\n",
    "            for xi in self.data[i]: #[][][][][][]\n",
    "                yi=i #-1,+1\n",
    "                print(xi,':',yi*(np.dot(self.w,xi)+self.b))            \n",
    "\n",
    "    def predict(self,features):\n",
    "        # sign( x.w+b )\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        if classification !=0 and self.visualization:\n",
    "            self.ax.scatter(features[0], features[1], s=200, marker='*', c=self.colors[classification])\n",
    "        return classification\n",
    "    \n",
    "    \n",
    "    def predict1(self,features):\n",
    "        # sign( x.w+b )\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        return classification\n",
    "\n",
    "    def visualize(self):\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "\n",
    "        # hyperplane = x.w+b\n",
    "        # v = x.w+b\n",
    "        # psv = 1\n",
    "        # nsv = -1\n",
    "        # dec = 0\n",
    "        def hyperplane(x,w,b,v):\n",
    "            return (-w[0]*x-b+v) / w[1]\n",
    "\n",
    "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "\n",
    "        # (w.x+b) = 1\n",
    "        # positive support vector hyperplane\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], 'k')\n",
    "\n",
    "        # (w.x+b) = -1\n",
    "        # negative support vector hyperplane\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], 'k')\n",
    "\n",
    "        # (w.x+b) = 0\n",
    "        # positive support vector hyperplane\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2], 'y--')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "data_dict = {-1:np.array([[1,7],\n",
    "                          [2,8],\n",
    "                          [3,8],]),\n",
    "             \n",
    "             1:np.array([[5,1],\n",
    "                         [6,-1],\n",
    "                         [7,3],])}\n",
    "\n",
    "svm = Support_Vector_Machine()\n",
    "svm.fit(data=data_dict)\n",
    "\n",
    "predict_us = [[0,10],\n",
    "              [1,3],\n",
    "              [3,4],\n",
    "              [3,5],\n",
    "              [5,5],\n",
    "              [5,6],\n",
    "              [6,-5],\n",
    "              [5,8]]\n",
    "print('new feature ------',svm.predict([[9,-5]]))\n",
    "\n",
    "\n",
    "for p in predict_us:\n",
    "    svm.predict(p)\n",
    "    print(svm.predict(p))\n",
    "\n",
    "svm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
